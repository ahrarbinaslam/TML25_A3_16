{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install & Import Libraries**"
      ],
      "metadata": {
        "id": "OqQTFrF0SB6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np8agZmPRNaL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torch.serialization import add_safe_globals"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "Abi0l6nlTP7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to load .pt file that was saved using TaskDataset\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "# Register class for deserialization\n",
        "add_safe_globals({'TaskDataset': TaskDataset})\n",
        "\n",
        "# Load dataset from .pt file\n",
        "dataset = torch.load(\"Train.pt\", weights_only=False)\n",
        "\n",
        "# Add transform (resize and normalize)\n",
        "transform_fn = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "dataset.transform = transform_fn\n",
        "\n",
        "# Data loader\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "SYkAogvcRneO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FGSM and PGD Attack**"
      ],
      "metadata": {
        "id": "kKmoEz7xTU8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FGSM attack function\n",
        "def fgsm(model, x, y, eps):\n",
        "    x.requires_grad = True\n",
        "    pred = model(x)\n",
        "    loss = nn.CrossEntropyLoss()(pred, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    adv_x = torch.clamp(x + eps * x.grad.sign(), 0, 1)\n",
        "    return adv_x\n",
        "\n",
        "# PGD attack function\n",
        "def pgd(model, x, y, eps=0.03, alpha=0.01, steps=3):\n",
        "    x_orig = x.detach().clone()\n",
        "    x_adv = x_orig + 0.001 * torch.randn_like(x_orig)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        x_adv.requires_grad = True\n",
        "        output = model(x_adv)\n",
        "        loss = nn.CrossEntropyLoss()(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        step = alpha * x_adv.grad.sign()\n",
        "        delta = torch.clamp(x_adv + step - x_orig, -eps, eps)\n",
        "        x_adv = torch.clamp(x_orig + delta, 0, 1).detach()\n",
        "\n",
        "    return x_adv"
      ],
      "metadata": {
        "id": "DP4Zz0zHSP1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "gCyOH2nZTZWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ResNet34 model\n",
        "model = models.resnet34(weights=None)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "# Device and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "epochs = 20\n",
        "epsilon = 0.03\n",
        "alpha = 0.01\n",
        "pgd_steps = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x_batch, y_batch in data_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Clean loss\n",
        "        out_clean = model(x_batch)\n",
        "        loss_clean = loss_fn(out_clean, y_batch)\n",
        "\n",
        "        # FGSM loss\n",
        "        x_fgsm = fgsm(model, x_batch, y_batch, epsilon)\n",
        "        out_fgsm = model(x_fgsm)\n",
        "        loss_fgsm = loss_fn(out_fgsm, y_batch)\n",
        "\n",
        "        # PGD loss\n",
        "        x_pgd = pgd(model, x_batch, y_batch, epsilon, alpha, pgd_steps)\n",
        "        out_pgd = model(x_pgd)\n",
        "        loss_pgd = loss_fn(out_pgd, y_batch)\n",
        "\n",
        "        # Combine and backprop\n",
        "        loss_total = (loss_clean + loss_fgsm + loss_pgd) / 3\n",
        "        loss_total.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss_total.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch+1:02d}/{epochs} | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"robust_model.pt\")\n",
        "print(\"Model saved to 'robust_model.pt'\")"
      ],
      "metadata": {
        "id": "PUh29_SxSQpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation Script to Load and Validate Model**"
      ],
      "metadata": {
        "id": "L3FXFnw9ThtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Evaluation Script #####\n",
        "allowed_models = {\"resnet18\": models.resnet18, \"resnet34\": models.resnet34,\"resnet50\": models.resnet50,}\n",
        "\n",
        "with open(\"robust_model.pt\", \"rb\") as f:\n",
        "    try:\n",
        "        eval_model = allowed_models[\"resnet34\"](weights=None)\n",
        "        eval_model.fc = nn.Linear(eval_model.fc.in_features, 10)\n",
        "    except Exception as err:\n",
        "        raise Exception(\n",
        "            f\"Model architecture not permitted. {err=}, allowed: {allowed_models.keys()}\"\n",
        "        )\n",
        "    try:\n",
        "        weights = torch.load(f, map_location=torch.device(\"cpu\"))\n",
        "        eval_model.load_state_dict(weights, strict=True)\n",
        "        eval_model.eval()\n",
        "        eval_model(torch.randn(1, 3, 32, 32))\n",
        "    except Exception as err:\n",
        "        raise Exception(f\"Model failed to load or execute. {err=}\")"
      ],
      "metadata": {
        "id": "wuPXeBEiSUpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Submission**"
      ],
      "metadata": {
        "id": "sfGmKr-4UN5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Submission ---\n",
        "import requests\n",
        "response = requests.post(\n",
        "    \"http://34.122.51.94:9090/robustness\",\n",
        "    files={\"file\": open(\"robust_model.pt\", \"rb\")},\n",
        "    headers={\"token\": \"93145372\", \"model-name\": \"resnet34\"}\n",
        ")\n",
        "print(\"Submission response:\", response.json())"
      ],
      "metadata": {
        "id": "fT38-x_HUNhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}